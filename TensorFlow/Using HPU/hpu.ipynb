{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright (c) 2021 Habana Labs, Ltd. an Intel Company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu",
    "tags": []
   },
   "source": [
    "## Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# Use an HPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoYIwe40vEPI"
   },
   "source": [
    "**An adaptation of [Use a GPU](https://www.tensorflow.org/guide/gpu) guide using Habana Gaudi AI processors.**\n",
    "\n",
    "TensorFlow code, and `tf.keras` models run on a single HPU (Gaudi) with only a few lines of code changes.\n",
    "\n",
    "Note: Use `tf.config.list_physical_devices('HPU')` to confirm that TensorFlow is using the HPU.\n",
    "\n",
    "The simplest way to run on multiple HPUs, on one or many machines, is using [Distribution Strategies](https://github.com/HabanaAI/Gaudi-tutorials/blob/main/TensorFlow/DistributedTraining/example_tf_strategy.ipynb). \n",
    "\n",
    "This guide is for users who have tried these approaches and found that they need fine-grained control of how TensorFlow uses the HPU. To learn how to debug performance issues for single and multi-HPU scenarios, see the [Model Performance Optimization](https://docs.habana.ai/en/latest/Model_Performance_Optimization/Model_Performance_Optimization_in_Habana_Gaudi.html?highlight=cpu%20performance#) guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Ensure you have the latest SynapseAI and supported TensorFlow release installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IqR2PQG4ZaZ0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqR2PQG4ZaZ0",
    "tags": []
   },
   "source": [
    "## Enable Habana\n",
    "Letâ€™s enable the Gaudi device by loading the Habana module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IqR2PQG4ZaZ0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:51:10.658540: W /home/jenkins/workspace/cdsoftwarebuilder/create-tensorflow-module---bpt-d/tensorflow-training/habana_device/helpers/op_registry_backdoor.cpp:92] Couldn't find definition of RemoteCall:GPU: to register on HPU\n"
     ]
    }
   ],
   "source": [
    "from habana_frameworks.tensorflow import load_habana_module\n",
    "load_habana_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IqR2PQG4ZaZ0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num HPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num HPUs Available: \", len(tf.config.list_physical_devices('HPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZELutYNetv-v"
   },
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "Habana TensorFlow supports running computations on CPU and HPU. They are represented with string identifiers for example:\n",
    "\n",
    "*   `\"/device:CPU:0\"`: The CPU of your machine.\n",
    "*   `\"/HPU:0\"`: Short-hand notation for the first HPU of your machine that is visible to TensorFlow.\n",
    "*   `\"/job:localhost/replica:0/task:0/device:HPU:0\"`: Fully qualified name of the first HPU of your machine that is visible to TensorFlow.\n",
    "\n",
    "If a TensorFlow operation has both CPU and HPU implementations, by default, the HPU device is prioritized when the operation is assigned. For example, `tf.matmul` has both CPU and HPU kernels and on a system with devices `CPU:0` and `HPU:0`, the `HPU:0` device is selected to run `tf.matmul` unless you explicitly request to run it on another device.\n",
    "\n",
    "If a TensorFlow operation has no corresponding HPU implementation, then the operation falls back to the CPU device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhNtHfuxCGVy"
   },
   "source": [
    "## Logging device placement\n",
    "\n",
    "To find out which devices your operations and tensors are assigned to, put\n",
    "`tf.debugging.set_log_device_placement(True)` as the first statement of your\n",
    "program. Enabling device placement logging causes any Tensor allocations or operations to be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T01:22:04.032946Z",
     "iopub.status.busy": "2021-09-24T01:22:04.032064Z",
     "iopub.status.idle": "2021-09-24T01:22:04.439357Z",
     "shell.execute_reply": "2021-09-24T01:22:04.438868Z"
    },
    "id": "2Dbw0tpEirCd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:51:10.730441: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:HPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:HPU:0\n",
      "Executing op _function_MatMul_2918744514792547455 in device /job:localhost/replica:0/task:0/device:HPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:51:13.237326: W /home/jenkins/workspace/cdsoftwarebuilder/create-tensorflow-module---bpt-d/tensorflow-training/habana_device/habana_device.cpp:201] HPU initialization done for library version 1.3.0_c61303b7_tf2.8.0\n",
      "2022-04-06 21:51:13.259458: I tensorflow/core/common_runtime/placer.cc:114] a_0: (_Arg): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.259483: I tensorflow/core/common_runtime/placer.cc:114] b_1: (_Arg): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.259496: I tensorflow/core/common_runtime/placer.cc:114] MatMul: (MatMul): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.259502: I tensorflow/core/common_runtime/placer.cc:114] HabanaEagerMsg: (HabanaEagerMsg): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.259507: I tensorflow/core/common_runtime/placer.cc:114] product_0_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:HPU:0\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKhmFeraTdEI"
   },
   "source": [
    "The above code will print an indication the `MatMul` op was executed on `HPU:0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U88FspwGjB7W"
   },
   "source": [
    "## Manual device placement\n",
    "\n",
    "If you would like a particular operation to run on a device of your choice\n",
    "instead of what's automatically selected for you, you can use `with tf.device`\n",
    "to create a device context, and all the operations within that context will\n",
    "run on the same designated device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T01:22:04.445467Z",
     "iopub.status.busy": "2021-09-24T01:22:04.444764Z",
     "iopub.status.idle": "2021-09-24T01:22:04.448541Z",
     "shell.execute_reply": "2021-09-24T01:22:04.448883Z"
    },
    "id": "8wqaQfEhjHit"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _function_MatMul_7595306614168636033 in device /job:localhost/replica:0/task:0/device:HPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:51:13.285843: I tensorflow/core/common_runtime/placer.cc:114] a_0: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2022-04-06 21:51:13.285867: I tensorflow/core/common_runtime/placer.cc:114] b_1: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2022-04-06 21:51:13.285875: I tensorflow/core/common_runtime/placer.cc:114] MatMul: (MatMul): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.285881: I tensorflow/core/common_runtime/placer.cc:114] HabanaEagerMsg: (HabanaEagerMsg): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.285887: I tensorflow/core/common_runtime/placer.cc:114] product_0_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:HPU:0\n",
      "2022-04-06 21:51:13.347018: W /home/jenkins/workspace/cdsoftwarebuilder/create-tensorflow-module---bpt-d/tensorflow-training/habana_device/habana_device_binding_iface.cpp:59] Found TensorFlow library with SHA256: 1f4e3d3c8f90c158c442f60b6b1fafd64cfb678fd7c4f954804e0ba91497c2a0\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the HPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ixO89gRjJUu"
   },
   "source": [
    "You will see that now `a` and `b` are assigned to `CPU:0`. Since a device was\n",
    "not explicitly specified for the `MatMul` operation, the TensorFlow runtime will\n",
    "choose one based on the operation and available devices (`HPU:0` in this\n",
    "example) and automatically copy tensors between devices if required."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gpu.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
